name: build-and-deploy

on:
  schedule:
    - cron: '0 3 * * *'
  workflow_dispatch:
    inputs:
      skip_harvest:
        description: 'Skip harvest and translation (rebuild only)'
        required: false
        default: false
        type: boolean
  push:
    branches:
      - main
  pull_request:
    branches:
      - "**"

concurrency:
  # Separate concurrency groups for push runs that are internal [skip ci] updates
  # so those do not cancel an in-flight build-and-deploy run.
  group: build-and-deploy-${{ github.ref }}-${{ (github.event_name == 'push' && contains(github.event.head_commit.message || '', '[skip ci]')) && 'skip' || 'run' }}
  cancel-in-progress: true

jobs:
  build:
    # Avoid infinite loops when the workflow commits seen.json with [skip ci]
    if: ${{ github.event_name != 'push' || !contains(github.event.head_commit.message, '[skip ci]') }}
    runs-on: ubuntu-latest
    permissions:
      contents: write
    steps:
      - name: Capture run metadata
        id: meta
        run: echo "started_at=$(date -u +%Y-%m-%dT%H:%M:%SZ)" >> $GITHUB_OUTPUT
      - name: Set Backblaze region (job-wide)
        run: echo "AWS_DEFAULT_REGION=us-west-004" >> $GITHUB_ENV
      - uses: actions/checkout@v4
        with:
          fetch-depth: 0
          persist-credentials: true
      - uses: actions/setup-python@v5
        with:
          python-version: '3.11'
          cache: 'pip'
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
      - name: "Preflight: Validate OpenRouter API key"
        env:
          OPENROUTER_API_KEY: ${{ secrets.OPENROUTER_API_KEY }}
        if: ${{ github.event_name != 'pull_request' }}
        run: |
          set -e
          echo "ðŸ”Ž Preflight check: validating OPENROUTER_API_KEY"
          python -m src.tools.env_diagnose --check || true
          python -m src.tools.env_diagnose --validate || {
            echo "âŒ OPENROUTER_API_KEY invalid or missing â€” failing early"
            exit 1
          }
      - name: "Preflight (PR): Non-fatal environment check"
        if: ${{ github.event_name == 'pull_request' }}
        run: |
          set -e
          echo "ðŸ”Ž PR preflight: diagnostics only (no key validation)"
          python -m src.tools.env_diagnose --check || true
      - name: Hydrate dedupe state from B2
        env:
          BACKBLAZE_KEY_ID: ${{ secrets.BACKBLAZE_KEY_ID }}
          BACKBLAZE_APPLICATION_KEY: ${{ secrets.BACKBLAZE_APPLICATION_KEY }}
          BACKBLAZE_S3_ENDPOINT: ${{ secrets.BACKBLAZE_S3_ENDPOINT }}
          BACKBLAZE_BUCKET: ${{ secrets.BACKBLAZE_BUCKET }}
          BACKBLAZE_PREFIX: ${{ secrets.BACKBLAZE_PREFIX }}
        run: |
          set -e
          if [ -z "${BACKBLAZE_KEY_ID}" ] || [ -z "${BACKBLAZE_APPLICATION_KEY}" ] || [ -z "${BACKBLAZE_S3_ENDPOINT}" ] || [ -z "${BACKBLAZE_BUCKET}" ]; then
            echo "â„¹ï¸ B2 credentials missing; skipping seen.json hydrate"
            exit 0
          fi
          python -m pip install --upgrade pip >/dev/null 2>&1 || true
          pip install awscli >/dev/null 2>&1 || true
          export AWS_ACCESS_KEY_ID="${BACKBLAZE_KEY_ID}"
          export AWS_SECRET_ACCESS_KEY="${BACKBLAZE_APPLICATION_KEY}"
          export AWS_DEFAULT_REGION=us-west-004
          DEST="s3://${BACKBLAZE_BUCKET}/${BACKBLAZE_PREFIX}state/seen.json"
          mkdir -p data
          if aws s3 ls "${DEST}" --endpoint-url "${BACKBLAZE_S3_ENDPOINT}" >/dev/null 2>&1; then
            echo "â¬‡ï¸  Hydrating seen.json from ${DEST}"
            aws s3 cp "${DEST}" data/seen.json --endpoint-url "${BACKBLAZE_S3_ENDPOINT}" --only-show-errors
          else
            echo "â„¹ï¸ No remote seen.json found; starting fresh"
          fi
      - name: Run lint (pull_request)
        if: ${{ github.event_name == 'pull_request' }}
        run: ruff check src tests
      - name: Run tests (pull_request)
        if: ${{ github.event_name == 'pull_request' }}
        run: python -m pytest tests/ -q
      - name: Run tests (blocking on schedule/manual)
        if: ${{ github.event_name == 'schedule' || (github.event_name == 'workflow_dispatch' && (github.event.inputs.skip_harvest || 'false') != 'true') }}
        run: python -m pytest tests/ -q
      - name: Skip tests (manual rebuild-only)
        if: ${{ github.event_name == 'workflow_dispatch' && (github.event.inputs.skip_harvest || 'false') == 'true' }}
        run: echo "â„¹ï¸ Skipping tests on manual rebuild-only (skip_harvest=true)"
      - name: Run tests (non-blocking on push)
        if: ${{ github.event_name == 'push' }}
        continue-on-error: true
        run: python -m pytest tests/ -q
      - name: Build pipeline (harvest/translate only)
        env:
          OPENROUTER_API_KEY: ${{ secrets.OPENROUTER_API_KEY }}
          DISCORD_WEBHOOK_URL: ${{ secrets.DISCORD_WEBHOOK_URL }}
          BRIGHTDATA_API_KEY: ${{ secrets.BRIGHTDATA_API_KEY }}
          BRIGHTDATA_ZONE: ${{ secrets.BRIGHTDATA_ZONE }}
          # Backblaze B2 (S3-compatible)
          BACKBLAZE_KEY_ID: ${{ secrets.BACKBLAZE_KEY_ID }}
          BACKBLAZE_APPLICATION_KEY: ${{ secrets.BACKBLAZE_APPLICATION_KEY }}
          BACKBLAZE_S3_ENDPOINT: ${{ secrets.BACKBLAZE_S3_ENDPOINT }}
          BACKBLAZE_BUCKET: ${{ secrets.BACKBLAZE_BUCKET }}
          BACKBLAZE_PREFIX: ${{ secrets.BACKBLAZE_PREFIX }}
        run: |
          set -e
          echo "ðŸš€ Starting build process..."

          # Default to skipping harvest during PR builds
          SKIP_HARVEST="${{ github.event_name == 'pull_request' && 'true' || (github.event.inputs.skip_harvest || 'false') }}"
          # Define CURR/PREV unconditionally for metadata/RECORDS_KEYS
          CURR=$(date -u +"%Y%m")
          PREV=$(date -u -d "-1 month" +"%Y%m")

          if [ "$SKIP_HARVEST" = "false" ]; then
            # Attempt ChinaXiv harvest via BrightData if credentials provided
            if [ -n "${BRIGHTDATA_API_KEY}" ] && [ -n "${BRIGHTDATA_ZONE}" ]; then
              echo "ðŸ“¥ Harvesting from ChinaXiv (BrightData)â€¦"
              echo "   Current month: $CURR"
              echo "   Previous month: $PREV"
              python -m src.harvest_chinaxiv_optimized --month "$CURR" || echo "âš ï¸ Harvest current month failed; continuing"
              python -m src.harvest_chinaxiv_optimized --month "$PREV" || echo "âš ï¸ Harvest previous month failed; continuing"
            else
              echo "â„¹ï¸ BrightData credentials not set; skipping harvest"
            fi
            echo "ðŸ” Preparing records for selection..."
            python .github/scripts/merge_current_prev_records.py

            echo "ðŸ“‹ Selecting new items (no limit)..."
            if [ -f data/records/_merged_current_prev.json ]; then
              python -m src.select_and_fetch --records data/records/_merged_current_prev.json --output data/selected.json || {
                echo "âš ï¸ Record selection failed, using empty selection";
                echo '[]' > data/selected.json;
              }
            else
              echo "âš ï¸ No records found to select";
              echo '[]' > data/selected.json;
            fi

          # Persist selection to B2 (dated + latest), then strictly read from B2 (skip on PRs)
          echo "ðŸ§­ Preparing selection in Backblaze B2..."
          CI_IS_PR="${{ github.event_name == 'pull_request' && 'true' || 'false' }}"
          if [ -n "${BACKBLAZE_KEY_ID}" ] && [ -n "${BACKBLAZE_APPLICATION_KEY}" ] && [ -n "${BACKBLAZE_S3_ENDPOINT}" ] && [ -n "${BACKBLAZE_BUCKET}" ]; then
            python -m pip install --upgrade pip >/dev/null 2>&1 || true
            pip install awscli >/dev/null 2>&1 || true
            export AWS_ACCESS_KEY_ID="${BACKBLAZE_KEY_ID}"
            export AWS_SECRET_ACCESS_KEY="${BACKBLAZE_APPLICATION_KEY}"
            export AWS_DEFAULT_REGION=us-west-004
              DEST="s3://${BACKBLAZE_BUCKET}/${BACKBLAZE_PREFIX}"
              DAY=$(date -u +"%Y-%m-%d")
              SELECT_KEY="selections/daily/${DAY}.json"
              aws s3 cp data/selected.json "${DEST}${SELECT_KEY}" --endpoint-url "${BACKBLAZE_S3_ENDPOINT}" || {
                echo "âŒ Failed to upload selection to B2";
                python -m src.tools.b2_alerts add "upload selection failed: ${SELECT_KEY}";
                exit 1;
              }
              # Write latest pointer JSON
              echo "{\"path\": \"${SELECT_KEY}\", \"run_id\": \"${GITHUB_RUN_ID}\", \"ts\": \"$(date -u +%Y-%m-%dT%H:%M:%SZ)\"}" > latest.json
              aws s3 cp latest.json "${DEST}selections/latest.json" --endpoint-url "${BACKBLAZE_S3_ENDPOINT}" || {
                echo "âŒ Failed to update selections/latest.json";
                python -m src.tools.b2_alerts add "update latest.json failed";
                exit 1;
              }
              # Strictly read back from B2 to ensure CI references B2, not local
              rm -f data/selected.json
              aws s3 cp "${DEST}${SELECT_KEY}" data/selected.json --endpoint-url "${BACKBLAZE_S3_ENDPOINT}" || {
                echo "âŒ Failed to pull selection from B2";
                python -m src.tools.b2_alerts add "download selection failed: ${SELECT_KEY}";
                exit 1;
              }
              export SELECT_KEY
              echo "SELECT_KEY=${SELECT_KEY}" >> $GITHUB_ENV
              echo "RECORDS_KEYS=records/chinaxiv_${CURR}.json;records/chinaxiv_${PREV}.json" >> $GITHUB_ENV
            else
              if [ "$CI_IS_PR" = "true" ]; then
                echo "â„¹ï¸ PR build: skipping B2 selection persist (secrets withheld). Using local data/selected.json."
              else
                echo "âŒ B2 secrets missing; cannot persist selection"
                python -m src.tools.b2_alerts add "B2 selection persist skipped: missing secrets"
                exit 1
              fi
            fi

            # Translate
            echo "ðŸŒ Running translation pipeline..."
            python -m src.pipeline --skip-selection --workers 20 --with-qa || {
              echo "âš ï¸ Translation failed, continuing with existing translations"
            }
          else
            echo "â„¹ï¸ Skipping harvest and translation (rebuild only)"
          fi
          
          echo "â„¹ï¸ Deferring render/index/pdf to post-hydration steps"

      - name: Publish validated/flagged/PDFs to B2 and write manifests
        if: ${{ github.event_name != 'pull_request' }}
        env:
          AWS_ACCESS_KEY_ID: ${{ secrets.BACKBLAZE_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.BACKBLAZE_APPLICATION_KEY }}
          B2_S3_ENDPOINT: ${{ secrets.BACKBLAZE_S3_ENDPOINT }}
          B2_BUCKET: ${{ secrets.BACKBLAZE_BUCKET }}
          B2_PREFIX: ${{ secrets.BACKBLAZE_PREFIX }}
          SELECT_KEY: ${{ env.SELECT_KEY }}
          RECORDS_KEYS: ${{ env.RECORDS_KEYS }}
          RUN_STARTED_AT: ${{ steps.meta.outputs.started_at }}
          B2_FAIL_ON_ERROR: 'true'
        run: |
          # Ensure AWS CLI signs requests for Backblaze region
          export AWS_DEFAULT_REGION=us-west-004
          python -m pip install --upgrade pip >/dev/null 2>&1 || true
          pip install awscli >/dev/null 2>&1 || true
          python -m src.tools.b2_publish || {
            echo "âŒ B2 publish failed";
            exit 1;
          }

      - name: Hydrate validated translations from B2 (pre-render)
        if: ${{ github.event_name != 'pull_request' }}
        env:
          BACKBLAZE_KEY_ID: ${{ secrets.BACKBLAZE_KEY_ID }}
          BACKBLAZE_APPLICATION_KEY: ${{ secrets.BACKBLAZE_APPLICATION_KEY }}
          BACKBLAZE_S3_ENDPOINT: ${{ secrets.BACKBLAZE_S3_ENDPOINT }}
          BACKBLAZE_BUCKET: ${{ secrets.BACKBLAZE_BUCKET }}
          BACKBLAZE_PREFIX: ${{ secrets.BACKBLAZE_PREFIX }}
        run: |
          set -e
          if [ -z "${BACKBLAZE_KEY_ID}" ] || [ -z "${BACKBLAZE_APPLICATION_KEY}" ] || [ -z "${BACKBLAZE_S3_ENDPOINT}" ] || [ -z "${BACKBLAZE_BUCKET}" ]; then
            echo "âŒ Missing B2 credentials for hydration";
            python -m src.tools.b2_alerts add "hydrate skipped: missing B2 credentials";
            exit 1;
          fi
          python -m pip install --upgrade pip >/dev/null 2>&1 || true
          pip install awscli >/dev/null 2>&1 || true
          if ! python scripts/hydrate_from_b2.py --target data/translated; then
            python -m src.tools.b2_alerts add "hydrate failed";
            python -m src.tools.b2_alerts flush || true
            exit 1;
          fi

      - name: Render site (post-hydration)
        run: |
          set -e
          echo "ðŸŽ¨ Rendering site from hydrated data..."
          python -m src.render
          echo "ðŸ” Building search index..."
          python -m src.search_index
          echo "ðŸ“„ Generating PDFs..."
          python -m src.make_pdf || echo "âš ï¸ PDF generation failed, continuing without PDFs"
      - name: Set up Node.js
        if: ${{ github.event_name != 'pull_request' }}
        uses: actions/setup-node@v4
        with:
          node-version: '20'
      - name: Deploy to Cloudflare Pages
        if: ${{ github.event_name != 'pull_request' }}
        env:
          CLOUDFLARE_API_TOKEN: ${{ secrets.CF_API_TOKEN }}
        run: |
          set -e
          echo "ðŸš€ Deploying to Cloudflare Pages..."
          
          echo "ðŸ“¦ Installing Wrangler CLI..."
          npm install -g wrangler || {
            echo "âŒ Failed to install Wrangler"
            exit 1
          }
          
          echo "ðŸŒ Deploying site..."
          wrangler pages deploy site --project-name chinaxiv-english || {
            echo "âŒ Deployment failed"
            exit 1
          }
          
          echo "âœ… Deployment completed successfully!"
      - name: Persist pipeline outputs to Backblaze B2 (JSON only)
        if: ${{ github.event_name != 'pull_request' }}
        env:
          AWS_ACCESS_KEY_ID: ${{ secrets.BACKBLAZE_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.BACKBLAZE_APPLICATION_KEY }}
          B2_S3_ENDPOINT: ${{ secrets.BACKBLAZE_S3_ENDPOINT }}
          B2_BUCKET: ${{ secrets.BACKBLAZE_BUCKET }}
          B2_PREFIX: ${{ secrets.BACKBLAZE_PREFIX }}
        run: |
          set -e
          if [ -z "${AWS_ACCESS_KEY_ID}" ] || [ -z "${AWS_SECRET_ACCESS_KEY}" ] || [ -z "${B2_S3_ENDPOINT}" ] || [ -z "${B2_BUCKET}" ]; then
            echo "â„¹ï¸ Backblaze B2 secrets not set; skipping persistence"
            exit 0
          fi
          python -m pip install --upgrade pip
          pip install awscli
          export AWS_DEFAULT_REGION=us-west-004
          DEST="s3://${B2_BUCKET}/${B2_PREFIX}"
          echo "ðŸ“¤ Persisting JSON outputs to ${DEST} via ${B2_S3_ENDPOINT}"
          if [ -d data/records ]; then
            aws s3 cp data/records "${DEST}records/" --recursive --exclude "*" --include "*.json" --endpoint-url "${B2_S3_ENDPOINT}" --only-show-errors
          fi
          if [ -d data/translated ]; then
            aws s3 cp data/translated "${DEST}translations/" --recursive --exclude "*" --include "*.json" --endpoint-url "${B2_S3_ENDPOINT}" --only-show-errors
          fi
          if [ -f data/selected.json ]; then
            aws s3 cp data/selected.json "${DEST}selections/${GITHUB_RUN_ID}/selected.json" --endpoint-url "${B2_S3_ENDPOINT}" --only-show-errors
          fi
      - name: Flush B2 alert buffer (if any)
        if: ${{ github.event_name != 'pull_request' }}
        run: |
          python -m src.tools.b2_alerts flush || true
      - name: Upload harvest artifacts (records + selection)
        if: ${{ github.event_name != 'pull_request' }}
        uses: actions/upload-artifact@v4
        with:
          name: harvest-data-${{ github.run_id }}
          if-no-files-found: ignore
          retention-days: 90
          path: |
            data/records/*.json
            data/selected.json
      - name: Persist dedupe state to B2 (seen.json)
        if: ${{ github.event_name != 'pull_request' }}
        env:
          AWS_ACCESS_KEY_ID: ${{ secrets.BACKBLAZE_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.BACKBLAZE_APPLICATION_KEY }}
          B2_S3_ENDPOINT: ${{ secrets.BACKBLAZE_S3_ENDPOINT }}
          B2_BUCKET: ${{ secrets.BACKBLAZE_BUCKET }}
          B2_PREFIX: ${{ secrets.BACKBLAZE_PREFIX }}
        run: |
          set -e
          if [ -z "${AWS_ACCESS_KEY_ID}" ] || [ -z "${AWS_SECRET_ACCESS_KEY}" ] || [ -z "${B2_S3_ENDPOINT}" ] || [ -z "${B2_BUCKET}" ]; then
            echo "â„¹ï¸ B2 credentials missing; skipping seen.json persist"
            exit 0
          fi
          if [ ! -f data/seen.json ]; then
            echo "â„¹ï¸ No seen.json found; nothing to persist"
            exit 0
          fi
          python -m pip install --upgrade pip >/dev/null 2>&1 || true
          pip install awscli >/dev/null 2>&1 || true
          export AWS_DEFAULT_REGION=us-west-004
          DEST="s3://${B2_BUCKET}/${B2_PREFIX}state"
          echo "ðŸ“¤ Uploading dedupe state to ${DEST}/seen.json"
          aws s3 cp data/seen.json "${DEST}/seen.json" --endpoint-url "${B2_S3_ENDPOINT}" --only-show-errors
          TS=$(date -u +"%Y%m%dT%H%M%SZ")
          aws s3 cp data/seen.json "${DEST}/history/seen-${TS}.json" --endpoint-url "${B2_S3_ENDPOINT}" --only-show-errors || true
