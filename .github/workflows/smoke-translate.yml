name: smoke-translate
# ============================================================================
# PURPOSE: Pre-backfill testing at scale using selection-based translation.
#
# USE CASES:
# - Validate pipeline changes before running full backfill
# - Test translation quality on a sample of papers
# - Verify parallelism and worker scaling
# - Optional site deployment after successful run
#
# HOW IT WORKS:
# 1. Uses existing harvested records (or auto-harvests if month specified)
# 2. Selects N papers via the selection pipeline
# 3. Translates in parallel using configurable worker count
# 4. Reports QA results and optionally deploys site
#
# COMPARISON TO OTHER WORKFLOWS:
# - translation-canary: Tests 3 fixed papers with fresh fetch (daily health check)
# - complete-paper: Processes individual papers with fresh fetch (ad-hoc)
# - smoke-translate: Tests N papers from selection (pre-backfill validation)
# - backfill: Full production run with B2 persistence (production)
#
# SECRETS REQUIRED:
# - OPENROUTER_API_KEY: Text translation (required)
# - BRIGHTDATA_API_KEY: Harvesting if month specified (optional)
# - DISCORD_WEBHOOK_URL: Alert notifications (optional)
# ============================================================================

on:
  workflow_dispatch:
    inputs:
      limit:
        description: 'Number of papers to translate'
        required: false
        default: '20'
      workers:
        description: 'Parallel workers'
        required: false
        default: '20'
      month:
        description: 'Month (YYYYMM) to source records from'
        required: false
      deploy:
        description: 'Deploy site after smoke run'
        required: false
        default: 'false'

jobs:
  smoke:
    runs-on: ubuntu-latest
    permissions:
      contents: write
    steps:
      - uses: actions/checkout@v4
        with:
          fetch-depth: 0
          persist-credentials: true
          lfs: true
      - uses: actions/setup-python@v5
        with:
          python-version: '3.11'
          cache: 'pip'
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
      - name: Validate environment
        env:
          OPENROUTER_API_KEY: ${{ secrets.OPENROUTER_API_KEY }}
        run: |
          python -m src.tools.env_diagnose --check || true
          python -m src.tools.env_diagnose --validate || {
            echo "❌ OPENROUTER_API_KEY invalid or missing"; exit 1; }
      - name: Run smoke translate
        env:
          OPENROUTER_API_KEY: ${{ secrets.OPENROUTER_API_KEY }}
          DISCORD_WEBHOOK_URL: ${{ secrets.DISCORD_WEBHOOK_URL }}
          BRIGHTDATA_API_KEY: ${{ secrets.BRIGHTDATA_API_KEY }}
          BRIGHTDATA_ZONE: ${{ secrets.BRIGHTDATA_ZONE }}
        run: |
          set -e
          LIM=${{ inputs.limit || '20' }}
          W=${{ inputs.workers || '20' }}
          M=${{ inputs.month || '' }}
          DEPLOY=${{ inputs.deploy || 'false' }}
          EXTRA=""
          if [ -n "$M" ]; then EXTRA="--month $M"; fi
          # If a month is provided but no records are present, try harvesting that month.
          if [ -n "$M" ] && [ ! -f "data/records/chinaxiv_${M}.json" ]; then
            if [ -n "${BRIGHTDATA_API_KEY}" ] && [ -n "${BRIGHTDATA_ZONE}" ]; then
              echo "No records for $M; harvesting via BrightData…"
              python -m src.harvest_chinaxiv_optimized --month "$M" || echo "Harvest failed; proceeding without"
            else
              echo "No records for $M and no BrightData creds; proceeding without harvest"
            fi
          fi
          if [ "$DEPLOY" = "true" ]; then DFLAG="--deploy"; else DFLAG=""; fi
          python scripts/smoke_translate.py --limit "$LIM" --workers "$W" $EXTRA --alert $DFLAG
      - name: Upload smoke artifacts
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: smoke-outputs
          path: |
            data/selected.json
            data/translated/*.json
            data/flagged/*.json

