name: backfill-month

on:
  workflow_dispatch:
    inputs:
      month:
        description: 'Month to backfill (YYYYMM)'
        required: true
      no_latest:
        description: 'Do not update selections/latest.json (default false)'
        required: false
        default: 'false'
      workers:
        description: 'Parallel translation workers'
        required: false
        default: '20'
      deploy:
        description: 'Deploy site after backfill (true/false)'
        required: false
        default: 'true'

jobs:
  backfill:
    runs-on: ubuntu-latest
    permissions:
      contents: write
    steps:
      - name: Capture run metadata
        id: meta
        run: echo "started_at=$(date -u +%Y-%m-%dT%H:%M:%SZ)" >> $GITHUB_OUTPUT
      - name: Set Backblaze region (job-wide)
        run: echo "AWS_DEFAULT_REGION=us-west-004" >> $GITHUB_ENV
      - uses: actions/checkout@v4
        with:
          fetch-depth: 0
          persist-credentials: true
      - uses: actions/setup-python@v5
        with:
          python-version: '3.11'
          cache: 'pip'
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
      - name: "Preflight: Validate OpenRouter API key"
        env:
          OPENROUTER_API_KEY: ${{ secrets.OPENROUTER_API_KEY }}
        run: |
          set -e
          echo "ðŸ”Ž Preflight check: validating OPENROUTER_API_KEY"
          python -m src.tools.env_diagnose --check || true
          python -m src.tools.env_diagnose --validate || {
            echo "âŒ OPENROUTER_API_KEY invalid or missing â€” failing early"
            exit 1
          }
      - name: Hydrate dedupe state from B2
        env:
          BACKBLAZE_KEY_ID: ${{ secrets.BACKBLAZE_KEY_ID }}
          BACKBLAZE_APPLICATION_KEY: ${{ secrets.BACKBLAZE_APPLICATION_KEY }}
          BACKBLAZE_S3_ENDPOINT: ${{ secrets.BACKBLAZE_S3_ENDPOINT }}
          BACKBLAZE_BUCKET: ${{ secrets.BACKBLAZE_BUCKET }}
          BACKBLAZE_PREFIX: ${{ secrets.BACKBLAZE_PREFIX }}
        run: |
          set -e
          if [ -z "${BACKBLAZE_KEY_ID}" ] || [ -z "${BACKBLAZE_APPLICATION_KEY}" ] || [ -z "${BACKBLAZE_S3_ENDPOINT}" ] || [ -z "${BACKBLAZE_BUCKET}" ]; then
            echo "â„¹ï¸ B2 credentials missing; skipping seen.json hydrate"
            exit 0
          fi
          python -m pip install --upgrade pip >/dev/null 2>&1 || true
          pip install awscli >/dev/null 2>&1 || true
          export AWS_ACCESS_KEY_ID="${BACKBLAZE_KEY_ID}"
          export AWS_SECRET_ACCESS_KEY="${BACKBLAZE_APPLICATION_KEY}"
          export AWS_DEFAULT_REGION=us-west-004
          DEST="s3://${BACKBLAZE_BUCKET}/${BACKBLAZE_PREFIX}state/seen.json"
          mkdir -p data
          if aws s3 ls "${DEST}" --endpoint-url "${BACKBLAZE_S3_ENDPOINT}" >/dev/null 2>&1; then
            echo "â¬‡ï¸  Hydrating seen.json from ${DEST}"
            aws s3 cp "${DEST}" data/seen.json --endpoint-url "${BACKBLAZE_S3_ENDPOINT}" --only-show-errors
          else
            echo "â„¹ï¸ No remote seen.json found; starting fresh"
          fi
      - name: Backfill month
        env:
          OPENROUTER_API_KEY: ${{ secrets.OPENROUTER_API_KEY }}
          DISCORD_WEBHOOK_URL: ${{ secrets.DISCORD_WEBHOOK_URL }}
          BRIGHTDATA_API_KEY: ${{ secrets.BRIGHTDATA_API_KEY }}
          BRIGHTDATA_ZONE: ${{ secrets.BRIGHTDATA_ZONE }}
          BACKBLAZE_KEY_ID: ${{ secrets.BACKBLAZE_KEY_ID }}
          BACKBLAZE_APPLICATION_KEY: ${{ secrets.BACKBLAZE_APPLICATION_KEY }}
          BACKBLAZE_S3_ENDPOINT: ${{ secrets.BACKBLAZE_S3_ENDPOINT }}
          BACKBLAZE_BUCKET: ${{ secrets.BACKBLAZE_BUCKET }}
          BACKBLAZE_PREFIX: ${{ secrets.BACKBLAZE_PREFIX }}
        run: |
          set -e
          echo "ðŸš€ Backfill for month: ${{ inputs.month }}"
          
          REC="data/records/chinaxiv_${{ inputs.month }}.json"
          if [ -f "$REC" ]; then
            echo "ðŸ“„ Found existing records: $REC â€” skipping harvest"
          else
            if [ -z "${BRIGHTDATA_API_KEY}" ] || [ -z "${BRIGHTDATA_ZONE}" ]; then
              echo "âŒ BrightData credentials are required for backfill (no existing $REC)"
              exit 1
            fi
            echo "ðŸ“¥ Harvesting (optimized) for ${{ inputs.month }}..."
            python -m src.harvest_chinaxiv_optimized --month "${{ inputs.month }}" || {
              echo "âŒ Harvest failed"
              exit 1
            }
            if [ ! -f "$REC" ]; then
              echo "âŒ Records not found after harvest: $REC"
              exit 1
            fi
          fi
          
          echo "ðŸ“‹ Selecting new items from $REC..."
          python -m src.select_and_fetch --records "$REC" --output data/selected.json || {
            echo "âŒ Selection failed"
            exit 1
          }

          echo "ðŸ§­ Persisting selection to B2 and re-reading from B2..."
          if [ -n "${BACKBLAZE_KEY_ID}" ] && [ -n "${BACKBLAZE_APPLICATION_KEY}" ] && [ -n "${BACKBLAZE_S3_ENDPOINT}" ] && [ -n "${BACKBLAZE_BUCKET}" ]; then
            python -m pip install --upgrade pip >/dev/null 2>&1 || true
            pip install awscli >/dev/null 2>&1 || true
            export AWS_ACCESS_KEY_ID="${BACKBLAZE_KEY_ID}"
            export AWS_SECRET_ACCESS_KEY="${BACKBLAZE_APPLICATION_KEY}"
            export AWS_DEFAULT_REGION=us-west-004
            DEST="s3://${BACKBLAZE_BUCKET}/${BACKBLAZE_PREFIX}"
            DAY=$(date -u +"%Y-%m-%d")
            SELECT_KEY="selections/daily/${DAY}.json"
            aws s3 cp data/selected.json "${DEST}${SELECT_KEY}" --endpoint-url "${BACKBLAZE_S3_ENDPOINT}" || {
              echo "âŒ Failed to upload selection to B2";
              python -m src.tools.b2_alerts add "upload selection failed: ${SELECT_KEY}";
              exit 1;
            }
            if [ "${{ inputs.no_latest }}" != "true" ]; then
              echo "{\"path\": \"${SELECT_KEY}\", \"run_id\": \"${GITHUB_RUN_ID}\", \"ts\": \"$(date -u +%Y-%m-%dT%H:%M:%SZ)\"}" > latest.json
              aws s3 cp latest.json "${DEST}selections/latest.json" --endpoint-url "${BACKBLAZE_S3_ENDPOINT}" || {
                echo "âŒ Failed to update selections/latest.json";
                python -m src.tools.b2_alerts add "update latest.json failed";
                exit 1;
              }
            fi
            rm -f data/selected.json
            aws s3 cp "${DEST}${SELECT_KEY}" data/selected.json --endpoint-url "${BACKBLAZE_S3_ENDPOINT}" || {
              echo "âŒ Failed to pull selection from B2";
              python -m src.tools.b2_alerts add "download selection failed: ${SELECT_KEY}";
              exit 1;
            }
            export SELECT_KEY
            echo "SELECT_KEY=${SELECT_KEY}" >> $GITHUB_ENV
          else
            echo "âŒ B2 secrets missing; cannot persist selection"
            python -m src.tools.b2_alerts add "B2 selection persist skipped: missing secrets"
            exit 1
          fi
          
          echo "ðŸŒ Translating (workers=${{ inputs.workers }})..."
          python -m src.pipeline --skip-selection --workers "${{ inputs.workers }}" --with-qa || {
            echo "âŒ Pipeline failed"
            exit 1
          }
          echo "âœ… Backfill and site build completed for ${{ inputs.month }}"
      - name: Publish validated/flagged/PDFs to B2 and write manifests
        env:
          AWS_ACCESS_KEY_ID: ${{ secrets.BACKBLAZE_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.BACKBLAZE_APPLICATION_KEY }}
          B2_S3_ENDPOINT: ${{ secrets.BACKBLAZE_S3_ENDPOINT }}
          B2_BUCKET: ${{ secrets.BACKBLAZE_BUCKET }}
          B2_PREFIX: ${{ secrets.BACKBLAZE_PREFIX }}
          SELECT_KEY: ${{ env.SELECT_KEY }}
          RECORDS_KEYS: records/chinaxiv_${{ inputs.month }}.json
          RUN_STARTED_AT: ${{ steps.meta.outputs.started_at }}
          B2_FAIL_ON_ERROR: 'true'
        run: |
          # Ensure AWS CLI signs requests for Backblaze region
          export AWS_DEFAULT_REGION=us-west-004
          python -m pip install --upgrade pip >/dev/null 2>&1 || true
          pip install awscli >/dev/null 2>&1 || true
          python -m src.tools.b2_publish || {
            echo "âŒ B2 publish failed";
            exit 1;
          }

      - name: Hydrate validated translations from B2 (pre-render)
        if: ${{ inputs.deploy == 'true' }}
        env:
          AWS_ACCESS_KEY_ID: ${{ secrets.BACKBLAZE_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.BACKBLAZE_APPLICATION_KEY }}
          BACKBLAZE_S3_ENDPOINT: ${{ secrets.BACKBLAZE_S3_ENDPOINT }}
          BACKBLAZE_BUCKET: ${{ secrets.BACKBLAZE_BUCKET }}
          BACKBLAZE_PREFIX: ${{ secrets.BACKBLAZE_PREFIX }}
        run: |
          set -e
          if [ -z "${AWS_ACCESS_KEY_ID}" ] || [ -z "${AWS_SECRET_ACCESS_KEY}" ] || [ -z "${BACKBLAZE_S3_ENDPOINT}" ] || [ -z "${BACKBLAZE_BUCKET}" ]; then
            echo "âŒ Missing B2 credentials for hydration";
            python -m src.tools.b2_alerts add "hydrate skipped: missing B2 credentials";
            exit 1;
          fi
          python -m pip install --upgrade pip >/dev/null 2>&1 || true
          pip install awscli >/dev/null 2>&1 || true
          export AWS_DEFAULT_REGION=us-west-004
          DEST="s3://${BACKBLAZE_BUCKET}/${BACKBLAZE_PREFIX}"
          echo "ðŸ§¯ Reset local translations (data/translated)"
          rm -rf data/translated && mkdir -p data/translated
          echo "â¬‡ï¸  Syncing validated translations from ${DEST}validated/translations ..."
          aws s3 sync "${DEST}validated/translations" data/translated --exclude "*" --include "*.json" --endpoint-url "${BACKBLAZE_S3_ENDPOINT}" --only-show-errors || true
          COUNT=$(ls -1 data/translated/*.json 2>/dev/null | wc -l | tr -d ' ')
          echo "Found ${COUNT} validated translation JSON files"
          if [ "${COUNT}" = "0" ]; then
            echo "âŒ No validated translations found after hydration";
            python -m src.tools.b2_alerts add "hydrate yielded zero translations";
            python -m src.tools.b2_alerts flush || true
            exit 1;
          fi

      - name: Render site (post-hydration)
        if: ${{ inputs.deploy == 'true' }}
        run: |
          set -e
          echo "ðŸŽ¨ Rendering site from hydrated data..."
          python -m src.render
          echo "ðŸ” Building search index..."
          python -m src.search_index
          echo "ðŸ“„ Generating PDFs..."
          python -m src.make_pdf || echo "âš ï¸ PDF generation failed, continuing without PDFs"
      - name: Persist pipeline outputs to Backblaze B2 (JSON only)
        env:
          AWS_ACCESS_KEY_ID: ${{ secrets.BACKBLAZE_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.BACKBLAZE_APPLICATION_KEY }}
          B2_S3_ENDPOINT: ${{ secrets.BACKBLAZE_S3_ENDPOINT }}
          B2_BUCKET: ${{ secrets.BACKBLAZE_BUCKET }}
          B2_PREFIX: ${{ secrets.BACKBLAZE_PREFIX }}
        run: |
          set -e
          if [ -z "${AWS_ACCESS_KEY_ID}" ] || [ -z "${AWS_SECRET_ACCESS_KEY}" ] || [ -z "${B2_S3_ENDPOINT}" ] || [ -z "${B2_BUCKET}" ]; then
            echo "â„¹ï¸ Backblaze B2 secrets not set; skipping persistence"
            exit 0
          fi
          python -m pip install --upgrade pip
          pip install awscli
          export AWS_DEFAULT_REGION=us-west-004
          DEST="s3://${B2_BUCKET}/${B2_PREFIX}"
          echo "ðŸ“¤ Persisting JSON outputs to ${DEST} via ${B2_S3_ENDPOINT}"
          if [ -f "data/records/chinaxiv_${{ inputs.month }}.json" ]; then
            aws s3 cp "data/records/chinaxiv_${{ inputs.month }}.json" "${DEST}records/" --endpoint-url "${B2_S3_ENDPOINT}" --only-show-errors
          fi
          if [ -d data/translated ]; then
            aws s3 cp data/translated "${DEST}translations/" --recursive --exclude "*" --include "*.json" --endpoint-url "${B2_S3_ENDPOINT}" --only-show-errors
          fi
          if [ -f data/selected.json ]; then
            aws s3 cp data/selected.json "${DEST}selections/${GITHUB_RUN_ID}/selected.json" --endpoint-url "${B2_S3_ENDPOINT}" --only-show-errors
          fi
      - name: Upload harvest artifacts (records + selection)
        uses: actions/upload-artifact@v4
        with:
          name: harvest-data-${{ inputs.month }}-${{ github.run_id }}
          if-no-files-found: ignore
          retention-days: 90
          path: |
            data/records/chinaxiv_${{ inputs.month }}.json
            data/selected.json
      - name: Persist dedupe state to B2 (seen.json)
        env:
          AWS_ACCESS_KEY_ID: ${{ secrets.BACKBLAZE_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.BACKBLAZE_APPLICATION_KEY }}
          B2_S3_ENDPOINT: ${{ secrets.BACKBLAZE_S3_ENDPOINT }}
          B2_BUCKET: ${{ secrets.BACKBLAZE_BUCKET }}
          B2_PREFIX: ${{ secrets.BACKBLAZE_PREFIX }}
        run: |
          set -e
          if [ -z "${AWS_ACCESS_KEY_ID}" ] || [ -z "${AWS_SECRET_ACCESS_KEY}" ] || [ -z "${B2_S3_ENDPOINT}" ] || [ -z "${B2_BUCKET}" ]; then
            echo "â„¹ï¸ B2 credentials missing; skipping seen.json persist"
            exit 0
          fi
          if [ ! -f data/seen.json ]; then
            echo "â„¹ï¸ No seen.json found; nothing to persist"
            exit 0
          fi
          python -m pip install --upgrade pip >/dev/null 2>&1 || true
          pip install awscli >/dev/null 2>&1 || true
          export AWS_DEFAULT_REGION=us-west-004
          DEST="s3://${B2_BUCKET}/${B2_PREFIX}state"
          echo "ðŸ“¤ Uploading dedupe state to ${DEST}/seen.json"
          aws s3 cp data/seen.json "${DEST}/seen.json" --endpoint-url "${B2_S3_ENDPOINT}" --only-show-errors
          TS=$(date -u +"%Y%m%dT%H%M%SZ")
          aws s3 cp data/seen.json "${DEST}/history/seen-${TS}.json" --endpoint-url "${B2_S3_ENDPOINT}" --only-show-errors || true
      - name: Deploy to Cloudflare Pages (optional)
        if: ${{ inputs.deploy == 'true' }}
        env:
          CLOUDFLARE_API_TOKEN: ${{ secrets.CF_API_TOKEN }}
        run: |
          set -e
          echo "ðŸš€ Deploying to Cloudflare Pages..."
          npm install -g wrangler
          wrangler pages deploy site --project-name chinaxiv-english
      - name: Flush B2 alert buffer (if any)
        run: |
          python -m src.tools.b2_alerts flush || true
          echo "âœ… Deployment completed"
